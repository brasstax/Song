# This runs separately from the normal docker compose so that if you need to bring
# the scraper up and down, you won't bring this up and down inadvertently; if you
# bring this up and down, it might keep trying to fetch tokens and then twitter
# might end up locking you out.
version: "3.9"
services:
  nitter:
    image: catfacts/nitter:latest
    hostname: nitter
    # You shouldn't need ports exposed once you have this working since you want to have this
    # in the same network as the scraper.
    ports:
      - "127.0.0.1:8080:8080"
    volumes:
      - ./nitter/nitter.example.conf:/src/nitter.conf:Z,ro
      - ./nitter/guest_accounts.jsonl:/src/guest_accounts.jsonl:Z,ro
    depends_on:
      - nitter-redis
    restart: unless-stopped
    healthcheck:
      test: wget -nv --tries 1 --spider http://localhost:8080/Jack/status/20 || exit 1
      interval: 300s
      timeout: 5s
      retries: 2
    user: "998:998"
    read_only: true
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    
  nitter-redis:
    image: redis:6-alpine
    hostname: nitter-redis
    command: redis-server --save 60 1 --loglevel warning
    volumes:
      - nitter-redis:/data
    restart: unless-stopped
    healthcheck:
      test: redis-cli ping
      interval: 30s
      timeout: 5s
      retries: 2
    user: "999:1000"
    read_only: true
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL

networks:
  scraper:

volumes:
  nitter-redis:
